[
  {
    "objectID": "01_dia1.html",
    "href": "01_dia1.html",
    "title": "Scripts - 08/09/2025",
    "section": "",
    "text": "library(pliman)\nlibrary(tidyverse)\nlibrary(ggridges)",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#import-and-display",
    "href": "01_dia1.html#import-and-display",
    "title": "Scripts - 08/09/2025",
    "section": "\n2.1 Import and Display",
    "text": "2.1 Import and Display\n\n2.1.1 Import Images\n\nimg &lt;- image_import(\"20231001_153711.jpg\")\nplot(img)\n\n\n\n\n\n\n\nTo import a list of images, use a vector of image names or the pattern argument. In the latter case, all images matching the specified pattern will be imported into a list.\n\nimg_list1 &lt;- image_import(c(\"20231001_153711.jpg\", \"20231001_160425.jpg\"))\n\n\n2.1.2 Display Images\nIndividual images are displayed with plot(). To combine images, use the image_combine() function. Users can input a comma-separated list of objects or a list of objects of the Image class.\n\n# Individual images\nplot(img)\n\n\n\n\n\n\n\n\n# Combine images\nimage_combine(img_list1)\n\n\n\n\n\n\n\npliman provides a set of image_*() functions for performing image manipulation and transformation of single images or a list of images based on the EBImage package.",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#resolution",
    "href": "01_dia1.html#resolution",
    "title": "Scripts - 08/09/2025",
    "section": "\n2.2 Resolution",
    "text": "2.2 Resolution\n\n2.2.1 Image Resolution (DPI)\nThe dpi() function performs an interactive function to calculate the image resolution based on a known distance entered by the user. To calculate the image resolution (DPI), the user should use the left mouse button to create a known distance line. This can be done, for example, using a known distance model, as follows.\n\n#  this only works in an interactive section\n(imgres &lt;- dpi(img))\n\n\n2.2.2 Resize an Image\nSometimes, it is necessary to resize high-resolution images to reduce computational effort and processing time. The image_resize() function is used to resize an image. The rel_size argument can be used to resize the image by relative size. For example, setting rel_size = 50 for a 1280 x 720 pixels image, the new image will have a size of 640 x 360 pixels.\n\nimage_dimension(img)\n\n── Image dimension ─────────────────────────────────────────────────────────────\n\n\nWidth : 799\n\n\nHeight: 600\n\nimg_resized &lt;- image_resize(img, rel_size = 50)\nimage_dimension(img_resized)\n\n── Image dimension ─────────────────────────────────────────────────────────────\n\n\nWidth : 400\n\n\nHeight: 300",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#apply-a-function-to-images",
    "href": "01_dia1.html#apply-a-function-to-images",
    "title": "Scripts - 08/09/2025",
    "section": "\n2.3 Apply a Function to Images",
    "text": "2.3 Apply a Function to Images\n\napply_fun_to_imgs(pattern = \"2023\",\n                  image_resize,\n                  rel_size = 50,\n                  dir_processed = \"smaller\",\n                  plot = FALSE)\n\n── Sequential processing of 6 images ───── Started on \"2025-09-08 | 19:38:19\" ──\n\n\n── Function `image_resize()` successfully applied to the images ────────────────",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#export",
    "href": "01_dia1.html#export",
    "title": "Scripts - 08/09/2025",
    "section": "\n2.4 Export",
    "text": "2.4 Export\nTo export images to the current directory, use the image_export() function. If a list of images is exported, the images will be saved considering the name and extension present in the list. If no extension is present, the images will be saved as *.jpg files.\n\nimage_export(img, \"img_exported.jpg\")\n\n# or a subfolder\nimage_export(img, \"test/img_exported.jpg\")",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#image-indexes",
    "href": "01_dia1.html#image-indexes",
    "title": "Scripts - 08/09/2025",
    "section": "\n3.1 Image Indexes",
    "text": "3.1 Image Indexes\nThe image_index() function constructs image indices using Red, Green, Blue, Red-Edge, and NIR bands.\n\n# Calculate indices\nindexes &lt;- image_index(img, index = c(\"R, G, B, GRAY, L, B-G/(B+G)\"))\n\nℹ Index \"B-G/(B+G)\" is not available. Trying to compute your own index.\n\n\n\n\n\n\n\n# Create a histogram with RGB values\nplot(indexes, type = \"density\")\n\n\n\n\n\n\n\nIn the case of the R index, the two peaks represent the leaf + reference (smaller peak) and the background (larger peak). The clearer the difference between these peaks, the better the image segmentation.",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#binary-images",
    "href": "01_dia1.html#binary-images",
    "title": "Scripts - 08/09/2025",
    "section": "\n3.2 Binary Images",
    "text": "3.2 Binary Images\nTo segment objects, pliman uses the threshold technique (Otsu, 1979)1, i.e., a cutoff point (considering pixel values) is chosen and the image is classified into two classes (foreground and background). Then, we have a binary image. We can produce this image with image_binary(). This binarization is the key process for all object analysis steps. The better t…\n\nimage_index(img, index = \"GRAY\")\n\n\n\n\n\n\notsu(indexes$GRAY)\n\n[1] 0.4567649\n\nbin &lt;- \n  image_binary(img,  \n               index = \"GRAY\")\n\n\n\n\n\n\n\nNote that some leaf pixels were considered background and some background pixels were considered foreground. We can improve this binarization by applying a morphological operation (such as median filter or oppening) and filling the holes with fill_hull = TRUE. See how changing the filter argument impacts the results.\n\nbin &lt;- image_binary(img, \n                    index = \"GRAY\", \n                    fill_hull = TRUE,\n                    plot =  FALSE)[[1]]\nbin2 &lt;- image_binary(img, \n                     index = \"GRAY\", \n                     fill_hull = TRUE,\n                     filter = 10,\n                     plot =  FALSE)[[1]]\nbin3 &lt;- image_binary(img, \n                     index = \"GRAY\",\n                     fill_hull = TRUE,\n                     opening = 10,\n                     plot =  FALSE)[[1]]\n\nimage_combine(bin, bin2, bin3, ncol = 3)",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#segmentation",
    "href": "01_dia1.html#segmentation",
    "title": "Scripts - 08/09/2025",
    "section": "\n3.3 Segmentation",
    "text": "3.3 Segmentation\nIn pliman, the following functions can be used to segment objects in images.\nimage_segment() to produce a segmented image (objects in the image and a white background). image_segment_iter() to segment an image interactively. image_segment_kmeans() to segment an image using the k-means algorithm. image_segment_manual() to segment an image manually. image_segment_mask() to segment an image with a mask.\nBoth functions segment the image based on the value of some image index, which can be one of the RGB channels or any operation with these channels.\n\n3.3.1 Image Indices\n\nimage_segment(img,\n              index = \"G\",\n              fill_hull = TRUE,\n              opening = 5)",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#object-analysis",
    "href": "01_dia1.html#object-analysis",
    "title": "Scripts - 08/09/2025",
    "section": "\n3.4 Object Analysis",
    "text": "3.4 Object Analysis\nThe key is to obtain the contour of the objects, so we work with polygons!\n\nA ‘polygon’ is a plane figure described by a finite number of straight line segments connected to form a closed chain (Singer, 1993)2.\n\nWe can then conclude that image objects can be expressed as polygons with n vertices. Pliman has a family of poly_*() functions that can be used to analyze polygons.\n\nsquare &lt;- draw_square() |&gt; poly_close()\n\n\n\n\n\n\npoly_area(square)\n\n[1] 4\n\npoly_perimeter(square)\n\n[1] 8\n\npolygon &lt;- draw_n_tagon(6)\n\n\n\n\n\n\npoly_area(polygon)\n\n[1] 2.598076\n\n\nn &lt;- c(6, 10, 50, 100, 1000, 100000)\nsapply(n, function(x){\n  draw_n_tagon(x) |&gt; poly_area()\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[1] 2.598076 2.938926 3.133331 3.139526 3.141572 3.141593\n\n\n\n\n3.4.1 Contour\n\nimg &lt;- image_import(\"leaves.jpg\")\nplot(img)\n\n# extract the contour\ncont &lt;- object_contour(img, index = \"B\", watershed = FALSE)\n\n\n\n\n\n\n# Number of contour pixels\nnrow(cont[[1]])\n\n[1] 980\n\n# contour coordinates\nhead(cont[[1]])\n\n     [,1] [,2]\n[1,]  195   25\n[2,]  195   26\n[3,]  194   27\n[4,]  193   27\n[5,]  192   27\n[6,]  191   27\n\n# polygon\nplot_polygon(cont[[1]])\n\n\n\n\n\n\n\n\n3.4.2 Measures\nIn the current version of pliman, you can calculate the following measures. For more details, see Chen & Wang (2005)3, Claude (2008)4, and Montero et al. (2009)5.\n\nArea\n\nThe area of a shape is calculated using the Shoelace formula (Lee and Lim, 2017)6, as follows:\n\\[\nA=\\frac{1}{2}\\left |\\sum_{i=1}^{n}\\left(x_{i} y_{i+1}-x_{i+1}y_{i}\\right)\\right|\n\\]\n\npoly_area(cont)\n\n[1] 60631.0 44430.5 44580.5 38990.0 93424.0 76965.5\n\n\n\nPerimeter\n\nThe perimeter is calculated as the sum of the Euclidean distance between all points of a shape. The distances can be obtained with poly_distpts().\n\npoly_perimeter(cont)\n\n       1        2        3        5       11       14 \n1153.798 2330.010 1139.602 1215.323 1188.651 1266.621 \n\n# perimeter of a circle with radius 2\ncircle &lt;- draw_circle(radius = 2, plot = FALSE)\npoly_perimeter(circle)\n\n[1] 12.56635\n\n# check the result\n2*pi*2\n\n[1] 12.56637\n\n\n\nCenter of mass\n\nThe center of mass of a shape, especially in two-dimensional space, represents the average position of all the points within that shape, weighted by their area (or mass if considering physical objects). It’s the point at which the entire area (or mass) of the shape can be thought to be concentrated. In practical terms, if you were to balance a cut-out of the shape on a pinpoint, the center of mass is the location where it would balance perfectly.\nIn a polygon (a shape made of straight-line segments), the center of mass is calculated by considering each segment’s contribution to the overall shape, and its coordinates (\\(C_x\\) and \\(C_y\\)) are given by\n\\[\n\\begin{aligned}\nC_x & =\\frac{1}{6 A} \\sum_{i=1}^n\\left(x_i+x_{i+1}\\right)\\left(x_i y_{i+1}-x_{i+1} y_i\\right) \\\\\nC_y & =\\frac{1}{6 A} \\sum_{i=1}^n\\left(y_i+y_{i+1}\\right)\\left(x_i y_{i+1}-x_{i+1} y_i\\right)\n\\end{aligned}\n\\] Where A, is the area given above.\n\nplot_polygon(cont[[1]])\n# centroid\ncent &lt;- apply(cont[[1]], 2, mean)\npoints(cent[1], cent[2], col = \"red\", pch = 19)  # Red dot for centroid\n\n# Center of mass\ncm &lt;- poly_mass(cont[[1]])\npoints(cm[1], cm[2], col = \"blue\", pch = 19)  # Blue dot for center of mass\nlegend(\"topright\",\n       legend = c(\"Centroid\", \"Center of Mass\"), \n       col = c(\"red\", \"blue\"), pch = 19)\n\n\n\n\n\n\n\n\nRadius\n\nThe radius of a pixel in the object’s contour is calculated as its distance to the center of mass of the object. These distances can be obtained with poly_centdist().\n\ndist &lt;- poly_centdist_mass(cont[[1]])\nx &lt;- c(cm[1], cont[[1]][1, 1])\ny &lt;- c(cm[2], cont[[1]][1, 2])\nd1 &lt;- sqrt(diff(x)^2 + diff(y)^2)\ndist[[1]]\n\n[1] 178.4624\n\nplot_polygon(cont[[1]])\npoints(cm[1], cm[2], col = \"blue\", pch = 19)  # Blue dot for center of mass\nsegments(x[1], y[1], x[2], y[2], col = \"blue\", lwd = 2)\n\n\n\n\n\n\nplot(dist, type = \"l\")\n\n\n\n\n\n\n\n\nLength and Width\n\nThe length and width of an object are calculated with poly_lw(), as the difference between the maximum and minimum of the x and y coordinates after the object has been aligned with poly_align().\n\n# wrong measures\nplot_polygon(cont[[1]])\nlw &lt;- apply(cont[[1]], 2, \\(x){range(x)})\nabline(v = lw[[1]], col = \"red\")\nabline(v = lw[[2]], col = \"red\")\nabline(h = lw[[3]], col = \"blue\")\nabline(h = lw[[4]], col = \"blue\")\n\n\n\n\n\n\n# Correct measures\naligned &lt;- poly_align(cont[[1]])\nlw &lt;- apply(aligned, 2, \\(x){range(x)})\nabline(v = lw[[1]], col = \"red\")\nabline(v = lw[[2]], col = \"red\")\nabline(h = lw[[3]], col = \"blue\")\nabline(h = lw[[4]], col = \"blue\")\n\n\n\n\n\n\ndiff(lw)\n\n         [,1]     [,2]\n[1,] 190.3641 475.6255\n\n# with poly_lw()\npoly_lw(cont[[1]])\n\n       length    width\n[1,] 475.6255 190.3641\n\n\n\nCircularity and Elongation\n\nCircularity (Montero et al. 2009)7 is also called shape compactness or a measure of the roundness of an object. It is given by \\(C = P^2 / A\\), where \\(P\\) is the perimeter and \\(A\\) is the area of the object.\n\npoly_perimeter(cont) ^2 / poly_area(cont)\n\n        1         2         3         5        11        14 \n 21.95659 122.18968  29.13142  37.88176  15.12343  20.84479 \n\npoly_circularity(cont)\n\n        1         2         3         5        11        14 \n 21.95659 122.18968  29.13142  37.88176  15.12343  20.84479 \n\n\nAs the above measurement depends on scale, normalized circularity can be used. In this case, it is assumed that a perfect circle has a circularity equal to 1. This measure is invariant under translation, rotation, and scale transformations, given by \\(Cn = P^2 / 4 \\pi A\\)\n\npoly_perimeter(circle) ^2 / (4 * pi * poly_area(circle))\n\n[1] 1.000003\n\npoly_circularity_norm(circle)\n\n[1] 0.9999967\n\npoly_circularity_norm(cont)\n\n        1         2         3         5        11        14 \n0.5723279 0.1028431 0.4313683 0.3317261 0.8309208 0.6028541 \n\n\npoly_elongation() Calculates the elongation of an object as 1 - width / length\n\npoly_elongation(circle)\n\n              [,1]\n[1,] -1.236173e-06\n\npoly_elongation(cont)\n\n           [,1]\n[1,] 0.59976047\n[2,] 0.07475182\n[3,] 0.47262292\n[4,] 0.77301835\n[5,] 0.15421772\n[6,] 0.34880080\n\n\n\nPerimeter Complexity (PVC)\n\nThe PVC is first calculated by smoothing the input contour using a specified number of iterations. The smoothed contour is then used to calculate the distances between corresponding points in the original and smoothed coordinates. These distances reflect the variations in contour shape after smoothing. The sum of these distances represents the global magnitude of the variations. Next, the sum of the distances is multiplied by the standard deviation of the distances to capture the dispersion or spread of th…\n\npoly_pcv(circle)\n\n[1] 7.878397e-05\n\npoly_pcv(cont)\n\n        1         2         3         5        11        14 \n0.4765559 2.0312072 2.2185019 0.7703953 0.3572519 0.7428847",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#known-resolution",
    "href": "01_dia1.html#known-resolution",
    "title": "Scripts - 08/09/2025",
    "section": "\n5.1 Known Resolution",
    "text": "5.1 Known Resolution\n\ndpi(leaves)\ncorrected &lt;- get_measures(leaves_meas, dpi = 416)\n# plot width and length\nplot_measures(corrected,\n              measure = \"width\",\n              col = \"green\",\n              hjust = -90)\nplot_measures(corrected, \n              measure = \"length\", \n              vjust = 60,\n              col = \"red\")",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#reference-object-color",
    "href": "01_dia1.html#reference-object-color",
    "title": "Scripts - 08/09/2025",
    "section": "\n5.2 Reference Object (color)",
    "text": "5.2 Reference Object (color)\nThe reference argument can now be used to correct the measurements of objects even when images with different capture distances are used. This differs from the previous example in a subtle but crucial aspect: when reference is informed, batch processing can be used! In this example, the leaf area of the leaves image is quantified and corrected considering a 4 x 5 (20 cm\\(^2\\)) rectangle as a reference object. When reference = TRUE is informed in analyze_objects(), the function will perform a two-step object segmentation process:\nThe first step consists of segmenting the foreground (leaves and reference object) from the background. For this, an image index is used and can be declared in the back_fore_index argument. The default (back_fore_index = \"R/(G/B)\") is optimized to segment white backgrounds of green leaves and a blue reference object. Let’s see the performance of this index in this example.\n\nind &lt;- image_index(leaves, index = \"R/(G/B)\", plot =  FALSE)[[1]]\n\nℹ Index \"R/(G/B)\" is not available. Trying to compute your own index.\n\nbin &lt;- image_binary(leaves, index = \"R/(G/B)\", plot =  FALSE)[[1]]\n\nℹ Index \"R/(G/B)\" is not available. Trying to compute your own index.\n\nimage_combine(ind, bin)\n\n\n\n\n\n\n# Segmenting the image\nseg1 &lt;- image_segment(leaves, index = \"R/(G/B)\")\n\n\n\n\n\n\n\nGood job! Now, we remove the background. The next step is to segment the objects and the reference model. Basically, we need to repeat the previous step isolating the reference.\n\nimage_segment(seg1, \"B-R\")\n\n\n\n\n\n\nseg2 &lt;- \n  image_binary(seg1,\n               index = \"B-R\")\n\nℹ Index \"B-R\" is not available. Trying to compute your own index.\n\n\n\n\n\n\n\n# number of pixels in the reference object\nlength(which(seg2$`B-R` != 1))\n\n[1] 517741\n\n\nNow that we know the indices to be used for each segmentation, we can use the analyze_objects function to obtain the corrected measurements based on the reference object.\n\nres2 &lt;- \n  analyze_objects(leaves, \n                  index = \"B\",\n                  reference = TRUE,\n                  reference_area = 20,\n                  back_fore_index = \"R/(G/B)\", # default\n                  fore_ref_index = \"B-R\",      # default\n                  marker = \"width\")\n\nℹ Processing a single image. Please, wait.\n\n\n\n\n\n\n\n\n✔ Image Successfully analyzed! [2.7s]",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#reference-object-size",
    "href": "01_dia1.html#reference-object-size",
    "title": "Scripts - 08/09/2025",
    "section": "\n5.3 Reference Object (size)",
    "text": "5.3 Reference Object (size)\nA second option for correcting the measurements is to use a reference object that is smaller or larger than all the objects in the image. When this is the case, the reference_larger and reference_smaller arguments can be used to indicate when the largest/smallest object in the image should be used as a reference object. This is only valid when reference is set to TRUE and reference_area indicates the area of the reference object. IMPORTANT. When reference_smaller is used, objects with an area smaller than 1% of the average of all objects are ignored. This is used to remove possible noise in the image, such as dust. Therefore, make sure that the reference object has an area that will not be removed by this cutoff point.\n\nflaxref &lt;- image_import(\"flax_ref.jpg\", plot = TRUE)\n\n\n\n\n\n\nres2 &lt;- \n  analyze_objects(flaxref,\n                  index = \"GRAY\",\n                  reference = TRUE,\n                  reference_area = 6,\n                  reference_larger = TRUE,\n                  show_contour = FALSE,\n                  marker = \"point\")\n\nℹ Processing a single image. Please, wait.\n\n\n\n\n\n\n\n\n✔ Image Successfully analyzed! [729ms]\n\n\n\n\nplot(res2)\n\n\n\n\n\n\nimage_view(flaxref, object = res2)\n\nWarning in CPL_crs_from_input(x): GDAL Message 1: +init=epsg:XXXX syntax is\ndeprecated. It might return a CRS with a non-EPSG compliant axis order. Further\nmessages of this type will be suppressed.\n\n\nWarning: Found less unique colors (5) than unique zcol values (44)! \nInterpolating color vector to match number of zcol values.",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#flax-leaves",
    "href": "01_dia1.html#flax-leaves",
    "title": "Scripts - 08/09/2025",
    "section": "\n7.1 Flax leaves",
    "text": "7.1 Flax leaves\nTo obtain the RGB/HSV intensity of each object in the image, use the argument object_rgb = TRUE in the function analyze_objects().In the following example, we use the R, G, and B bands and their normalized values.The function pliman_indexes() returns the indexes available in the package.\nTo calculate a specific index, simply insert a formula containing the values of R, G, or B (e.g., object_index = “B/G+R”).\n\nimg &lt;- image_import(\"flax.jpg\", plot = TRUE)\nplot(img)\n(indx &lt;- pliman_indexes_rgb())\n\n [1] \"B\"     \"BGI\"   \"BI\"    \"BI2\"   \"CI\"    \"CIVE\"  \"EGVI\"  \"ERVI\"  \"G\"    \n[10] \"GB\"    \"GD\"    \"GLAI\"  \"GLI\"   \"GR\"    \"GRAY\"  \"GRAY2\" \"HI\"    \"HUE\"  \n[19] \"HUE2\"  \"I\"     \"L\"     \"MGVRI\" \"NB\"    \"NG\"    \"NGBDI\" \"NGRDI\" \"NR\"   \n[28] \"R\"     \"RB\"    \"RI\"    \"S\"     \"SAVI\"  \"SCI\"   \"SHP\"   \"SI\"    \"VARI\" \n[37] \"BCC\"   \"BRVI\"  \"GCC\"   \"GRVI2\" \"IPCA\"  \"MVARI\" \"NDI\"   \"RCC\"   \"RGBVI\"\n[46] \"TGI\"   \"VEG\"   \"vNDVI\" \"WI\"   \n\nflax_leaves &lt;-\n  analyze_objects(img,\n                  index = \"B\",\n                  opening = 5,\n                  object_index = c(\"DGCI\", \"CIVE\", \"ERVI\", \"EGVI\", \"R\", \"G\", \"B\"),\n                  pixel_level_index = TRUE,\n                  marker = \"id\")\n\nℹ Processing a single image. Please, wait.\n\n\n\n\n\n\n\n\n✔ Image Successfully analyzed! [5.4s]\n\n\n\n\n# PCA with the indexes\nind &lt;- summary_index(flax_leaves, type=\"var\")\n\nWarning in sqrt(eigenvalue): NaNs produzidos\n\n\n\n\n\n\n\n\nNow, let’s plot the DGCI (Dark Green Color Index) on each object. The DGCI is based on the HSB (Hue, Saturation, and Brightness) spatial color and has been used as an indicator of green shade 9\n\nimage_view(img, \n           object = flax_leaves,\n           color_regions = custom_palette(c(\"yellow\", \"darkgreen\")),\n           attribute = \"DGCI\")\n\nℹ Using downsample = 2 so that the number of rendered pixels approximates max_pixels.\n\n\nWarning: Found less unique colors (5) than unique zcol values (170)! \nInterpolating color vector to match number of zcol values.",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#color-texture",
    "href": "01_dia1.html#color-texture",
    "title": "Scripts - 08/09/2025",
    "section": "\n7.2 Color Texture",
    "text": "7.2 Color Texture\nDefinitions and interpretations of various texture features calculated from the Gray Level Co-occurrence Matrix (GLCM).\n\nASM (Angular Second Moment):\nDefinition: Measures the uniformity or energy of the texture, calculated as the sum of squared elements in the GLCM.\nInterpretation: Higher values indicate a more uniform texture; lower values suggest more variation.\nCON (Contrast):\nDefinition: Measures local variations in the GLCM, calculating intensity contrast between a pixel and its neighbor.\nInterpretation: High values indicate textures with sharp edges or strong intensity variations.\nCOR (Correlation):\nDefinition: Assesses the linear dependency of gray levels between neighboring pixels, measuring how correlated a pixel is to its neighbors.\nInterpretation: High values indicate strong correlation, suggesting a predictable texture pattern.\nVAR (Variance):\nDefinition: Measures the dispersion of gray levels in the GLCM, quantifying how much gray levels differ from the mean.\nInterpretation: High variance indicates a wide range of intensity values, suggesting a more complex texture.\nIDM (Inverse Difference Moment) or Local Homogeneity:\nDefinition: Measures the homogeneity of the texture, assigning higher weights to smaller gray-level differences.\nInterpretation: Higher values indicate a more homogenous texture.\nSAV (Sum Average):\nDefinition: Calculates the average of the sums of gray levels in the GLCM.\nInterpretation: Reflects the average intensity of pixel pairs.\nSVA (Sum Variance):\nDefinition: Measures the variability of the sum distribution in the GLCM.\nInterpretation: High values indicate a wide spread of the sum distribution.\nSEN (Sum Entropy):\nDefinition: Measures the randomness of the sum distribution in the GLCM.\nInterpretation: High values indicate high randomness in the texture.\nDVA (Difference Variance):\nDefinition: Measures the variability of the difference distribution in the GLCM.\nInterpretation: High values suggest varied and complex texture patterns.\nDEN (Difference Entropy):\nDefinition: Measures the randomness of the difference distribution in the GLCM.\nInterpretation: High values indicate high unpredictability in the texture differences.\nF12 (Difference Variance):\nDefinition: Another representation of Difference Variance, measuring the spread of differences in gray levels.\nF13 (Angular Second Moment):\nDefinition: Another representation of ASM, measuring the uniformity of the texture.\n\nThese features help in analyzing textures by quantifying uniformity, contrast, and randomness, crucial in applications like image classification and pattern recognition.\n\nimgtest &lt;- \n  image_import(c(\"beans/G166.jpg\",\n                 \"beans/G799.jpg\"),\n               plot = TRUE)\n\n\n\n\n\n\n# Gray images\nimage_index(imgtest[[1]], \"GRAY\")\n\n\n\n\n\n\nimage_index(imgtest[[2]], \"GRAY\")\n\n\n\n\n\n\n# Angular Second Moment\nres &lt;- \n  lapply(imgtest, function(x){\n    analyze_objects(x,\n                    index = \"B-R\",\n                    haralick = TRUE, # texture features\n                    har_band = \"GRAY\",\n                    marker = \"dva\",\n                    marker_col = \"green\", \n                    marker_size = 3,\n                    opening = 3,\n                    watershed = FALSE)\n  })\n\nℹ Processing a single image. Please, wait.\n\n\n\n\n\n\n\n\n✔ Image Successfully analyzed! [642ms]\n\n\n\n\n\nℹ Processing a single image. Please, wait.\n\n\n\n\n\n\n\n\n✔ Image Successfully analyzed! [562ms]\n\n\n\n\n# Batch Processing\nres &lt;- \n  analyze_objects(pattern = \"G\",\n                  dir_original = \"beans\",\n                  index = \"B-R\",\n                  haralick = TRUE, # texture features\n                  marker_col = \"green\", \n                  opening = 10,\n                  watershed = FALSE,\n                  object_index = c(\"L\", \"a\", \"b*\"),\n                  parallel = TRUE)\n\n── Parallel processing using 3 cores ─────── Started on 2025-09-08 | 19:42:23 ──\n\n\nℹ Processing 55 images found on 'D:/Desktop/UFSC/NEPEM/c...itacao_imganalise/be…\n\n\n███████████████████████████████    2% | ETA: 13m\n\n\n███████████████████████████████   36% | ETA: 28s\n\n\n███████████████████████████████   51% | ETA: 18s\n\n\n███████████████████████████████   73% | ETA:  8s\n\n\n███████████████████████████████   91% | ETA:  3s\n\n\n███████████████████████████████  100% | ETA:  0s\n\n\nℹ Processing 55 images found on 'D:/Desktop/UFSC/NEPEM/c...itacao_imganalise/be…\n✔ Batch processing finished [29.1s]\n\n⠙ Binding the results.\n\n\n┌ Global statistics  ──────────────────────────────────────────────┐\n│                                                                  │\n│   Total objects: 281            Total area: 7950970              │\n│   Overall mean area: 28295.27   Overall SD: 9217.13              │\n│   Min area: 6358                Max area: 51688                  │\n│                                                                  │\n└──────────────────────────────────────────────────────────────────┘\n┌ Across-image statistics (per-image averages) ────────────────────┐\n│                                                                  │\n│   Avg objects: 5.11             Avg sum area: 144563.09          │\n│   Min objects: 5                Max objects: 9                   │\n│   Avg area: 28465.66            Avg SD area: 4603.52             │\n│   Min mean area: 8219           Max mean area: 40847.6           │\n│                                                                  │\n└─────────────────────────────────────────────── Based on 0 images ┘\n\n\n── Processing successfully finished ──────────────── on 2025-09-08 | 19:42:52 ──\n⠙ Binding the results.\n✔ Binding the results. [281ms]\n\ndfpca &lt;- \n  left_join(res$results, res$object_index) |&gt; \n  select(img, L, a, `b*`, ent) |&gt; \n  group_by(img) |&gt; \n  summarise(across(where(is.numeric), mean)) |&gt; \n  column_to_rownames(\"img\")\n\nJoining with `by = join_by(img, id)`\n\nlibrary(factoextra)\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nlibrary(FactoMineR)\n\na &lt;- metan::clustering(dfpca, scale = TRUE)\n\nfviz_dend(a$hc, k = 5)\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\nℹ The deprecated feature was likely used in the factoextra package.\n  Please report the issue at &lt;https://github.com/kassambara/factoextra/issues&gt;.\n\n\n\n\n\n\n\npcam &lt;- PCA(dfpca, graph = FALSE)\nfviz_pca_biplot(pcam, repel = TRUE)\n\n\n\n\n\n\n\n\nimg &lt;- image_import(\"feijoes.jpg\", resize = 50)\nscatt &lt;-\n  object_scatter(\n    img,\n    index = \"B-R\",\n    watershed = FALSE,\n    erosion = 15,\n    filter = 10,\n    object_index = c(\"L\", \"a\", \"b*\"),\n    x = \"L\",\n    y = \"ent\",\n    haralick = TRUE,\n    show_id = FALSE,\n    xlab = \"Luminosidade\",\n    ylab = \"Entropia da GLCM\",\n    scale = 0.15,\n    xy_ratio = 1.5\n  )\n\nℹ Getting cached data...\n\n\n✔ Getting cached data... [2.3s]\n\n\n\n\n\nℹ Putting objects in their positions...\n\n\n\n\n\n\n\n\n✔ Putting objects in their positions... [347ms]",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#pollen-counting-and-viability",
    "href": "01_dia1.html#pollen-counting-and-viability",
    "title": "Scripts - 08/09/2025",
    "section": "\n8.1 Pollen Counting and Viability",
    "text": "8.1 Pollen Counting and Viability\nImage available in this discussion\n\nimg &lt;- image_import(\"pollen.jpg\", plot = TRUE)\nres &lt;-\n  analyze_objects(img,\n                  filter = 2,\n                  tolerance = 0.5,\n                  lower_noise = 0.3,\n                  show_contour = FALSE,\n                  index = \"L*\")\n\nℹ Processing a single image. Please, wait.\n\n\n✔ Image Successfully analyzed! [1.3s]\n\n\n\n\nsize &lt;- res$results\nids &lt;- size[size$area &gt; 580, ]\nids2 &lt;- size[size$area &lt;= 580, ]\npoints(ids$x, ids$y, pch = 16)\npoints(ids2$x, ids2$y, pch = 16, col = \"yellow\")\n\n\nlegend(\"top\",\n       c(\"Viable\", \"Not Viable\"),\n       pch = 16,\n       ncol = 2,\n       col = c(\"black\", \"yellow\"))\nprop &lt;- nrow(ids) / (nrow(ids) + nrow(ids2)) * 100\ntext(1020, -100,\n     labels = paste0(\"Count:\", res$statistics$value[1]))\ntext(1100, -60,\n     labels = paste0(\"Viable Pollen: \", round(prop, 3), \"%\"))",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#counting-corn-kernels-on-cobs",
    "href": "01_dia1.html#counting-corn-kernels-on-cobs",
    "title": "Scripts - 08/09/2025",
    "section": "\n8.2 Counting Corn Kernels on Cobs",
    "text": "8.2 Counting Corn Kernels on Cobs\n\nimg &lt;- image_import(\"maize.jpg\", plot = TRUE)\n\n\n\n\n\n\ncrop &lt;- \n  img |&gt; \n  image_crop(height = 52:1006,\n             plot = TRUE)\n\nres &lt;-\n  analyze_objects(crop,\n                  filter = 10,\n                  index = \"R\",\n                  show_lw = TRUE,\n                  invert = TRUE,\n                  width_at = TRUE,\n                  watershed = FALSE)\n\nℹ Processing a single image. Please, wait.\n\n\n\n\n\n\n\n\n✔ Image Successfully analyzed! [1.5s]\n\n\n\n\n# largura ao longo do comprimento\npar(mfrow = c(1, 4))\na &lt;- lapply(res$contours, poly_width_at, at = \"height\", plot = TRUE)\n\n\n\n\n\n\npar(mfrow = c(1,1))\n\n# Counting the Kernels\nseg &lt;- image_segment(crop,\n                     filter = 20,\n                     index = \"R-B\",\n                     col_background = \"gray\",\n                     invert = TRUE)\n\n\n\n\n\n\nimage_index(seg, \"L*\")\n\n\n\n\n\n\nres &lt;-\n  analyze_objects_shp(seg,\n                      ncol = 4,\n                      threshold = \"adaptive\",\n                      windowsize = 33,\n                      tolerance = 1,\n                      index = \"L*-a\",\n                      marker = \"point\",\n                      marker_col = \"black\",\n                      invert = TRUE,\n                      plot = TRUE,\n                      upper_size = 1200)\n\nℹ Processing a single image. Please, wait.\n\n\n✔ Image Successfully analyzed! [2.1s]\n\n\n\n\n\nℹ Processing a single image. Please, wait.\n\n\n✔ Image Successfully analyzed! [686ms]\n\n\n\n\n\nℹ Processing a single image. Please, wait.\n\n\n✔ Image Successfully analyzed! [617ms]\n\n\n\n\n\nℹ Processing a single image. Please, wait.\n\n\n✔ Image Successfully analyzed! [510ms]\n\n\n\n\n\nℹ Processing a single image. Please, wait.\n\n\n\n\n\n\n\n\n✔ Image Successfully analyzed! [522ms]\n\n\n\n\n# A correction factor will be needed here. Note that only nearly a half of the ear is analyzed\nres$statistics |&gt; \n  filter(stat == \"n\")\n\n   img stat value\n1 shp1    n   233\n2 shp2    n   219\n3 shp3    n   180\n4 shp4    n   202",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#fourier-descriptors",
    "href": "01_dia1.html#fourier-descriptors",
    "title": "Scripts - 08/09/2025",
    "section": "\n8.3 Fourier Descriptors",
    "text": "8.3 Fourier Descriptors\nThe available functions for contour analysis using Elliptical Fourier Descriptors were adapted from Claude (2088)10\nThe following example shows how to extract Fourier descriptors from sweet potato leaves, derived from an experiment conducted by the NEOSC group at UFSC.\n\nimg &lt;- image_import(\"potato.jpg\") \n\n# Contours\ncont &lt;- object_contour(img,\n                       index = \"R\",\n                       plot = FALSE,\n                       watershed = FALSE)\n# removing the reference\nplot_polygon(cont)\n\n\n\n\n\n\ncont &lt;- cont[-which(names(cont) == \"9\")]\nplot_polygon(cont)\n\n\n\n\n\n\n# Compute the Fourier descriptors\nfourier &lt;- efourier(cont, nharm = 30)\nfourier_inv5 &lt;- efourier_inv(fourier, nharm = 5)\nfourier_inv10 &lt;- efourier_inv(fourier, nharm = 10)\nfourier_inv20 &lt;- efourier_inv(fourier, nharm = 20)\n\n# Plot the estimated contour with different harmonics\nplot(img)\nplot_contour(cont, col = \"red\", lwd = 1)\nplot_contour(fourier_inv5, col = \"blue\", lwd = 3)\nplot_contour(fourier_inv10, col = \"green\", lwd = 3)\nplot_contour(fourier_inv20, col = \"salmon\", lwd = 3)\n\n\n\n\n\n\n# or using the analyze_objects() function\n# Contours\nres &lt;- \n  analyze_objects(img, \n                  marker = \"id\",\n                  watershed = FALSE,\n                  reference = TRUE,\n                  reference_area = 20,\n                  efourier = TRUE,\n                  nharm = 15,\n                  plot = FALSE)\n\nℹ Processing a single image. Please, wait.\n\n\n✔ Image Successfully analyzed! [1.9s]\n\n\n\n\nimage_view(img,\n           object = res,\n           alpha = 0.3,\n           attribute = \"solidity\")\n\nℹ Using downsample = 2 so that the number of rendered pixels approximates max_pixels.\n\n\nWarning: Found less unique colors (5) than unique zcol values (7)! \nInterpolating color vector to match number of zcol values.\n\n\n\n\n\ncoefs &lt;- res$efourier_norm\n\npca &lt;- \n  coefs |&gt; \n  select(id:D15) |&gt; \n  pliman::column_to_rownames(\"id\") |&gt; \n  select(-A1)\n\nlibrary(factoextra)\nlibrary(FactoMineR)\npcam &lt;- PCA(pca, graph = FALSE)\nfviz_pca_ind(pcam)",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#using-color-palettes",
    "href": "01_dia1.html#using-color-palettes",
    "title": "Scripts - 08/09/2025",
    "section": "\n9.1 Using Color Palettes",
    "text": "9.1 Using Color Palettes\nColor palettes can be created simply by manually sampling small areas of representative images and producing a composite image representing each desired class (background, healthy tissue, and symptomatic tissue). The following image11 shows symptoms of anthracnose (Elsinoë ampelina) on grape leaves.\n\nimg &lt;- image_import(pattern = \"videira\", plot = TRUE)\n\n\n\n\n\n\n# putting image names into quotes \"\" says to pliman to search such image in the working directory\nsev &lt;- measure_disease(\"videira\",\n                       img_healthy = \"videira_healthy\",\n                       img_symptoms = \"videira_disease\",\n                       img_background = \"videira_background\")\n\nℹ Processing a single image. Please, wait.\n\n\n\n\n\n\n\n\n✔ Image Successfully analyzed! [1.2s]\n\n\n\n\nsev$severity\n\n   healthy symptomatic\n1 85.10615    14.89385",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#using-image-indices",
    "href": "01_dia1.html#using-image-indices",
    "title": "Scripts - 08/09/2025",
    "section": "\n9.2 Using Image Indices",
    "text": "9.2 Using Image Indices\n\ngrape &lt;- img$videira.png\nimage_index(grape, c(\"B\", \"R\", \"G\", \"NGRDI\"))\n\n\n\n\n\n\nseg &lt;- image_segment(as_image(grape@.Data[,,1:3]), \"B\",\n                     fill_hull = TRUE)\n\n\n\n\n\n\nsev2 &lt;-\n  measure_disease(\"videira\",\n                  index_lb = \"G\",\n                  index_dh = \"NGRDI\",\n                  contour_col = \"red\",\n                  opening = c(0, 5),\n                  threshold = c(\"Otsu\", 0),\n                  # show_original = FALSE,\n                  show_features = TRUE,\n                  save_image = FALSE,\n                  show_segmentation = TRUE,\n                  watershed = TRUE)\n\nℹ Processing a single image. Please, wait.\n\n\n\n\n\n\n\n\n✔ Image Successfully analyzed! [1.5s]\n\n\n\n\nsev2$severity\n\n   healthy symptomatic\n1 89.55889    10.44111",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#batch-processing-1",
    "href": "01_dia1.html#batch-processing-1",
    "title": "Scripts - 08/09/2025",
    "section": "\n9.3 Batch Processing",
    "text": "9.3 Batch Processing\nTo analyze multiple images from a directory, use the pattern argument to declare a pattern for file names. Here, 50 soybean leaves available in the repository https://osf.io/4hbr6, a database of plant disease severity annotation images, will be used. Thanks to Emerson M. Del Ponte and his collaborators for making this project publicly available. Using the save_image = TRUE argument saves the processed images in a temporary directory defined by tempdir().\n\n# create a temporary directory\n\nsev_batch &lt;-\n  measure_disease(pattern = \"soy\",\n                  dir_original = \"sevsoja\",\n                  dir_processed = \"sevproc\",\n                  index_lb = \"B\",\n                  index_dh = \"NGRDI\",\n                  threshold = c(\"Otsu\", -0.03),\n                  plot =  FALSE,\n                  parallel = TRUE)\n\n── Parallel processing using 3 cores ───── Started on \"2025-09-08 | 19:43:36\" ──\n\n\nℹ Processing 50 images in parallel...\n\n\n███████████████████████████████    2% | ETA:  5m\n\n\n███████████████████████████████    6% | ETA:  4m\n\n\n███████████████████████████████   66% | ETA:  9s\n\n\n███████████████████████████████   86% | ETA:  3s\n\n\n███████████████████████████████  100% | ETA:  0s\n\n\nℹ Processing 50 images in parallel...\n── Processing successfully finished ──────────────── on 2025-09-08 | 19:43:59 ──\nℹ Processing 50 images in parallel...\n✔ Batch processing finished [23.5s]\n\nsev_batch$severity |&gt;\n  ggplot(aes(x = symptomatic)) +\n  geom_histogram(bins = 8)",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#multiple-leaves-in-an-image",
    "href": "01_dia1.html#multiple-leaves-in-an-image",
    "title": "Scripts - 08/09/2025",
    "section": "\n9.4 Multiple Leaves in an Image",
    "text": "9.4 Multiple Leaves in an Image\nWhen multiple leaves are present in an image, the measure_disease function returns the average severity of the leaves in the image. To quantify severity per leaf, the measure_disease_byl() function can be used.\nThis function calculates the percentage of symptomatic leaf area using color palettes or RGB indices for each leaf (byl) in an image. This allows, for example, processing replicates of the same treatment and obtaining results for each replicate with a single image.\nIn the following example, images of orange leaves, kindly provided by Gabriele de Jesus, are processed.\n\nimg &lt;- image_import(\"sev_leaves.jpg\", plot = TRUE)\n\n\n\n\n\n\nsev &lt;-\n  measure_disease_byl(img,\n                      index = \"B\",\n                      index_lb = \"B\",\n                      index_dh = \"NGRDI\")\n\nℹ Processing a single image. Please, wait.\nℹ Processing a single image. Please, wait.\n\n\n\n\n\n\n\n\n✔ Image Successfully analyzed! [651ms]\n\n\n\n\n\nℹ Processing a single image. Please, wait.\nℹ Processing a single image. Please, wait.\n\n\n\n\n\n\n\n\n✔ Image Successfully analyzed! [950ms]\n\nℹ Processing a single image. Please, wait.\nℹ Processing a single image. Please, wait.\n\n\n\n\n\n\n\n\n✔ Image Successfully analyzed! [708ms]\n\nℹ Processing a single image. Please, wait.\nℹ Processing a single image. Please, wait.\n\n\n\n\n\n\n\n\n✔ Image Successfully analyzed! [684ms]\n\nℹ Processing a single image. Please, wait.\n✔ Image Successfully analyzed! [4.8s]\n\nsev$severity\n\n  img leaf  healthy symptomatic\n1 img    1 59.26646    40.73354\n2 img    2 59.62619    40.37381\n3 img    3 60.08614    39.91386\n4 img    4 57.36590    42.63410",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#dose-response-curves",
    "href": "01_dia1.html#dose-response-curves",
    "title": "Scripts - 08/09/2025",
    "section": "\n9.5 Dose-Response Curves",
    "text": "9.5 Dose-Response Curves\nThe provided script deals with data analysis of a dose-response experiment to evaluate the effectiveness of different products in reducing the severity of a plant disease. The use of images is authorized by SUMITOMO-SA.\nThe first step is to quantify the severity within each petri dish, which represents a dose of a particular product. Subsequently, to fit the curves, the analysis is performed using the drda library in R, which is a tool for dose-response data analysis.\nThe script fits nonlinear regression models to dose-response data using the drda() function for each product. The specified model is a 4-parameter log-logistic regression (“ll4”).\n\n# DOSE-RESPONSE\n# Compute severity per leaf\nsev &lt;-\n  measure_disease_byl(pattern = \"img\",\n                      index = \"B\",\n                      index_dh = \"NGRDI\",\n                      dir_original = \"dose_response\",\n                      parallel = TRUE,\n                      opening = c(25, 0))\n\n── Parallel processing of 14 images ────── Started at \"2025-09-08 | 19:44:07\" ──\n\n\nℹ Dispatching batches...\n\n\n███████████████████████████████    7% | ETA:  3m\n\n\n███████████████████████████████   29% | ETA:  1m\n\n\n███████████████████████████████  100% | ETA:  0s\n\n\nℹ Dispatching batches...\n✔ All batches complete! [33.2s]\n\nres &lt;- \n  map_dfr(sev, function(x){\n    x$severity\n  })\n\nsevres &lt;- \n  res |&gt;\n  separate(img, into = c(\"img\", \"product\", \"dose\"), sep = \"_\") |&gt;\n  mutate(dose = as.numeric(str_replace_all(dose, \",\", \".\")),\n         symptomatic = symptomatic / 100)\n\nmodels &lt;-\n  sevres |&gt;\n  group_by(product) |&gt;\n  nest() |&gt;\n  mutate(models = map(data,\n                      ~drda(symptomatic ~ dose,\n                            data = .,\n                            mean_function = \"ll4\"))) |&gt; # define the model here\n  dplyr::select(-data)\n\n# function to obtain the coefficients\nget_results &lt;- function(model,\n                        resplevel = 0.5,\n                        type = \"relative\"){\n  coefs &lt;- coef(model) |&gt; t()\n  ed &lt;- effective_dose(model, y = resplevel) |&gt; as.data.frame()\n  integ &lt;- data.frame(nauc = nauc(model, range(model$model[[2]])))\n  cbind(coefs, ed, integ)\n}\n\n# Obtain the coefficients\n# alpha:  the value of the function at x = 0\n# delta: height of the curve\n# eta: the steepness (growth rate) of the curve\n# phi: the x value at which the curve is equal to its mid-point\n\ncoefs &lt;-\n  models |&gt;\n  mutate(coefs = map_dfr(\n    .x = models,\n    .f = ~get_results(., resplevel = 0.5)) # DL50\n  ) |&gt;\n  dplyr::select(-models) |&gt;\n  unnest(coefs) |&gt;\n  ungroup() |&gt;\n  as.data.frame()\n\ncoefs\n\n  product     alpha      delta       eta       phi  Estimate Lower .95\n1      P1 0.3968639 -0.3864929 1.3703455 1.8071352 1.8071352 1.1849347\n2      P2 0.3821491 -0.3715773 0.9932846 0.4335226 0.4335226 0.2893241\n  Upper .95       nauc\n1 2.4293356 0.02744016\n2 0.5777211 0.01948812\n\nplot(models$models[[1]], models$models[[2]],\n     level = 0,\n     base = \"10\",\n     ylim = c(0, 0.5),\n     xlim = c(0, 100),\n     legend = c(\"P1\", \"P2\"),\n     xlab = \"Dose (ppm)\",\n     ylab = \"Disease Severity\",\n     col = metan::ggplot_color(2),\n     cex = 2)\n\n\n\n\n\n\n# derivative with respect to dose of the model\nD(expression(alpha + delta * x^eta / (x^eta + phi^eta)), \"x\")\n\ndelta * (x^(eta - 1) * eta)/(x^eta + phi^eta) - delta * x^eta * \n    (x^(eta - 1) * eta)/(x^eta + phi^eta)^2\n\ndy &lt;- function(x,alpha,  delta,   eta,   phi){\n  delta * (x^(eta - 1) * eta)/(x^eta + phi^eta) - delta * x^eta *\n    (x^(eta - 1) * eta)/(x^eta + phi^eta)^2\n}\n\n# First derivative\nggplot(data.frame(x = c(0, 5)), aes(x = x)) +\n  pmap(coefs |&gt; select(product:phi), function(product, alpha, delta, eta, phi) {\n    stat_function(fun = function(x) dy(x, alpha, delta, eta, phi),\n                  aes(color = product),\n                  linewidth = 1)\n  }) +\n  geom_vline(aes(xintercept = phi,\n                 color = product),\n             data = coefs,\n             linetype = 2) +\n  labs(x = \"Dose (ppm)\",\n       y = \"Severity Reduction Rate (% per ppm)\",\n       color = \"Product\") +\n  ggthemes::theme_base()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_function()`).",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#fungi-in-petri-dishes",
    "href": "01_dia1.html#fungi-in-petri-dishes",
    "title": "Scripts - 08/09/2025",
    "section": "\n9.6 Fungi in Petri Dishes",
    "text": "9.6 Fungi in Petri Dishes\n\n# fungi in petri dish\nfungi &lt;- image_import(\"fungi.jpg\", plot = TRUE)\n\n\n\n\n\n\nimage_index(fungi, \"L\")\n\n\n\n\n\n\nanalyze_objects(fungi,\n                index = \"L\",\n                filter  = 15,\n                watershed = FALSE,\n                contour_size  = 3,\n                invert = TRUE) |&gt;\n  get_measures(dpi = 90) |&gt;\n  plot_measures(measure = \"area\",\n                col = \"black\",\n                size = 2)\n\nℹ Processing a single image. Please, wait.\n\n\n✔ Image Successfully analyzed! [704ms]",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#bacteria",
    "href": "01_dia1.html#bacteria",
    "title": "Scripts - 08/09/2025",
    "section": "\n9.7 Bacteria",
    "text": "9.7 Bacteria\n\nbac &lt;- image_import(\"bacteria.jpg\", plot = TRUE)\nres &lt;- \n  analyze_objects(bac,\n                  index = \"L*\",\n                  threshold = 0.3,\n                  marker = \"point\")\n\nℹ Processing a single image. Please, wait.\n\n\n\n\n\n\n\n\n✔ Image Successfully analyzed! [693ms]\n\n\n\n\nres$statistics\n\n       stat        value\n1         n 1.780000e+02\n2  min_area 3.000000e+00\n3 mean_area 2.754494e+01\n4  max_area 8.200000e+01\n5   sd_area 1.467735e+01\n6  sum_area 4.903000e+03\n7  coverage 3.064375e-02",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "01_dia1.html#footnotes",
    "href": "01_dia1.html#footnotes",
    "title": "Scripts - 08/09/2025",
    "section": "Footnotes",
    "text": "Footnotes\n\nOtsu, N. 1979. Threshold selection method from gray-level histograms. IEEE Trans Syst Man Cybern SMC-9(1): 62–66. doi: 10.1109/tsmc.1979.4310076.↩︎\nSource: http://gazeta-rs.com.br/as-principais-doencas-da-videira-na-primavera/#prettyPhoto↩︎\nKarcher, D.E., and M.D. Richardson. 2003. Quantifying Turfgrass Color Using Digital Image Analysis. Crop Science 43(3): 943–951. doi: 10.2135/cropsci2003.9430↩︎\nClaude, J. 2008. Morphometrics with R https://link.springer.com/book/10.1007/978-0-387-77789-4↩︎\nMontero, RS, E. Bribiesca, R. Santiago, and E. Bribiesca. 2009. State of the Art of Compactness and Circularity Measures. International Mathematical Forum 4(27): 1305–1335.↩︎\nLee, Y., and W. Lim. 2017. Shoelace Formula: Connecting the Area of a Polygon and the Vector Cross Product. The Mathematics Teacher 110(8): 631–636. doi: 10.5951/MATHTEACHER.110.8.0631.↩︎\nMontero, R.S., E. Bribiesca, R. Santiago, and E. Bribiesca. 2009. State of the Art of Compactness and Circularity Measures. International Mathematical Forum 4(27): 1305–1335↩︎\nSource: http://gazeta-rs.com.br/as-principais-doencas-da-videira-na-primavera/#prettyPhoto↩︎\nKarcher, D.E., and M.D. Richardson. 2003. Quantifying Turfgrass Color Using Digital Image Analysis. Crop Science 43(3): 943–951. doi: 10.2135/cropsci2003.9430↩︎\nClaude, J. 2008. Morphometrics with R https://link.springer.com/book/10.1007/978-0-387-77789-4↩︎\nSource: http://gazeta-rs.com.br/as-principais-doencas-da-videira-na-primavera/#prettyPhoto↩︎",
    "crumbs": [
      "About",
      "Scripts - 08/09/2025"
    ]
  },
  {
    "objectID": "00_about.html",
    "href": "00_about.html",
    "title": "Useful Information!",
    "section": "",
    "text": "This material provides the scripts and datasets necessary to reproduce the examples presented in the Plant Image Analysis Course, offered as part of NEPEM’s internal training program\n\n1 Software\nTo reproduce the examples in this material, you will need the latest versions o R and RStudio (Portuguese).\n\n Download R\n Download RStudio\n\n2 Restoring the R environment with renv\nThis command will install all required packages with the exact versions recorded in the renv.lock file.\n\ninstall.packages(\"renv\")\nrenv::activate()\nrenv::restore()\n\nIf you later add new packages, run:\n\nrenv::snapshot()\n\n\n3 Citation\n\nTo cite the pliman package in your works, use the following reference:\n\nOlivoto T (2022). “Lights, camera, pliman! An R package for plant image analysis.” Methods in Ecology and Evolution, 13(4), 789-798. doi:10.1111/2041-210X.13803 https://doi.org/10.1111/2041-210X.13803.\n\n\ncitation(\"pliman\")\n\nPlease, support this project by citing it in your publications!\n\n  Olivoto T (2022). \"Lights, camera, pliman! An R package for plant\n  image analysis.\" _Methods in Ecology and Evolution_, *13*(4),\n  789-798. doi:10.1111/2041-210X.13803\n  &lt;https://doi.org/10.1111/2041-210X.13803&gt;.\n\nUma entrada BibTeX para usuários(as) de LaTeX é\n\n  @Article{,\n    title = {Lights, camera, pliman! An R package for plant image analysis},\n    author = {Tiago Olivoto},\n    year = {2022},\n    journal = {Methods in Ecology and Evolution},\n    volume = {13},\n    number = {4},\n    pages = {789-798},\n    doi = {10.1111/2041-210X.13803},\n  }\n\n\n\n4 Scripts\nThe .zip file contains a folder with the static website, structured as follows:\n\n\nD:/Desktop/UFSC/NEPEM/capacitações/capacitacao_imganalise\n├── 00_about.qmd\n├── 00_about.rmarkdown\n├── 01_dia1.qmd\n├── 20231001_144226.jpg\n├── 20231001_153711.jpg\n├── 20231001_160425.jpg\n├── 20231003_144448.jpg\n├── 20231005_112708.jpg\n├── 20231005_140911.jpg\n├── bacteria.jpg\n├── beans\n│   ├── G1042.jpg\n│   ├── G1080.jpg\n│   ├── G1083.jpg\n│   ├── G1106.jpg\n│   ├── G1113.jpg\n│   ├── G1149.jpg\n│   ├── G1173.jpg\n│   ├── G1205.jpg\n│   ├── G1261.jpg\n│   ├── G1264.jpg\n│   ├── G1265.jpg\n│   ├── G1320.jpg\n│   ├── G1328.jpg\n│   ├── G1354.jpg\n│   ├── G1356.jpg\n│   ├── G1358.jpg\n│   ├── G148.jpg\n│   ├── G166.jpg\n│   ├── G169.jpg\n│   ├── G229.jpg\n│   ├── G275.jpg\n│   ├── G278.jpg\n│   ├── G433.jpg\n│   ├── G478.jpg\n│   ├── G478A.jpg\n│   ├── G57.jpg\n│   ├── G623.jpg\n│   ├── G685.jpg\n│   ├── G686.jpg\n│   ├── G731.jpg\n│   ├── G734.jpg\n│   ├── G735.jpg\n│   ├── G738.jpg\n│   ├── G747.jpg\n│   ├── G753.jpg\n│   ├── G76.jpg\n│   ├── G799.jpg\n│   ├── G801.jpg\n│   ├── G803.jpg\n│   ├── G811.jpg\n│   ├── G818.jpg\n│   ├── G840.jpg\n│   ├── G842.jpg\n│   ├── G843.jpg\n│   ├── G847.jpg\n│   ├── G855.jpg\n│   ├── G857.jpg\n│   ├── G87.jpg\n│   ├── G908.jpg\n│   ├── G917.jpg\n│   ├── G92.jpg\n│   ├── G955.jpg\n│   ├── G983.jpg\n│   ├── G994.jpg\n│   └── G995.jpg\n├── capa.jpg\n├── capacitacao_imganalise.Rproj\n├── capsulas.jpg\n├── dose_response\n│   ├── img_P1_0,01.JPG\n│   ├── img_P1_0,1.JPG\n│   ├── img_P1_0.JPG\n│   ├── img_P1_1.JPG\n│   ├── img_P1_10.JPG\n│   ├── img_P1_100.JPG\n│   ├── img_P1_50.JPG\n│   ├── img_P2_0,01.JPG\n│   ├── img_P2_0,1.JPG\n│   ├── img_P2_0.JPG\n│   ├── img_P2_1.JPG\n│   ├── img_P2_10.JPG\n│   ├── img_P2_100.JPG\n│   └── img_P2_50.JPG\n├── feijoes.jpg\n├── flax.jpg\n├── flax2.jpg\n├── flax_capsules\n│   ├── 00a9b780-f098-44c5-aca7-5c77501e18a8.jpg\n│   ├── 07e8fdca-1759-40bc-8980-7f4d1e615fdf.jpg\n│   ├── 0ae6225f-2f07-493f-95fe-e4269cbdad04.jpg\n│   ├── 0ed81196-d1a7-43a3-931e-fe89b9900d69.jpg\n│   ├── 1a7003e4-9875-4ea8-a997-72e2aac9609f.jpg\n│   ├── 1d3d59fe-b2be-4b3a-9591-23f0e8fc3050.jpg\n│   ├── 1e026706-6791-4c23-b303-6dfb992de42a.jpg\n│   ├── 1ef7aa9f-6d88-42c0-a368-c412922c01ad.jpg\n│   ├── 2bd6eeee-17d9-404d-8773-5d57e58f64ed.jpg\n│   ├── 2f14ceef-5911-44b7-a6bc-18ddde1af0e1.jpg\n│   ├── 3b1121ba-0537-4633-bd51-072b735b0505.jpg\n│   ├── 3b8afc6f-1d77-4a5a-94c6-f711db3ddeba.jpg\n│   ├── 3d0d5f74-b940-42a6-a25c-015d4173f008.jpg\n│   ├── 3d17e772-6f86-4da7-a63a-c62bee734473.jpg\n│   ├── 3d7da214-4fb3-47a6-9537-94594c2d5ec9.jpg\n│   ├── 3e655e2f-4fe4-45d9-850f-bfe3e8745efb.jpg\n│   ├── 3eca5ca7-32a4-4d9f-a2a2-0935bac4515d.jpg\n│   ├── 4a687771-5efe-4d17-b2d9-dcec925b2303.jpg\n│   ├── 4bb0e537-f199-4d0a-8a39-d83d4c9701c0.jpg\n│   ├── 4c268db3-5281-44f0-868e-906f7f1272c4.jpg\n│   ├── 4dfccab2-1131-45b5-b7c9-4b0b1b4351b5.jpg\n│   ├── 4e52db5c-7995-48ee-9403-cff399d58478.jpg\n│   ├── 5a656b43-cc88-42a3-baa2-4570191311c3.jpg\n│   ├── 5aa4e11b-70df-427a-b385-6b83159d493a.jpg\n│   ├── 5ae8b265-9e47-4b8e-8188-add077c06ceb.jpg\n│   ├── 5b8d4be8-018a-4352-9ce7-dc8ad05ee212.jpg\n│   ├── 5d46b89e-55ba-488d-9943-72fee6d7703b.jpg\n│   ├── 5d6a82d3-73b0-47f2-8e1d-2608e9f50801.jpg\n│   ├── 5fecda17-4962-4993-9b1b-53fcc63f9817.jpg\n│   ├── 6ab11a67-acdf-45cb-a137-512a54c1b186.jpg\n│   ├── 6aec1433-98ee-447a-aadb-42c5bdfd1c72.jpg\n│   ├── 6ba1454f-bad6-4b1b-b01c-bbee963d01f1.jpg\n│   ├── 6bd11461-3ccc-4515-b4b4-8bdeae3476db.jpg\n│   ├── 6cfef61f-d030-43be-aeaf-8e4982bf1ebf.jpg\n│   ├── 6d40d5e9-1f86-4c3b-bfc6-8031c52bd804.jpg\n│   ├── 6e258ac8-8bf4-4351-906f-4fb8b8d37adb.jpg\n│   ├── 6f1c0231-ba12-472d-bd0a-fa505aa84563.jpg\n│   ├── 6fe29997-6522-46e3-92b3-1dcbf0549cb8.jpg\n│   ├── 7b7b10f2-bb3a-4de5-85b5-fe58c1849f15.jpg\n│   ├── 7e1b2853-e6f9-42fb-ab72-6613200f5d61.jpg\n│   ├── 8dae31df-8b4f-48f1-96dd-ac8e584fdd1b.jpg\n│   ├── 8ff14fb7-245b-4609-b34e-0bdcb532a7b5.jpg\n│   ├── 8ff43058-f7f3-4bec-acff-9feabd9eaddd.jpg\n│   ├── 9b158211-ec56-4938-ad4c-68f35f8fcc7c.jpg\n│   ├── 9b8c1000-1a2a-4595-8bff-455cedac64af.jpg\n│   ├── 9bdadeba-444a-4e16-9a7b-ebf19178f334.jpg\n│   ├── 9cfb5cf6-87e6-4705-9d28-bb8e316a3809.jpg\n│   ├── 9da02a71-c64b-42e4-8767-98211ecf957f.jpg\n│   ├── 9db67654-2fed-4dd0-b73c-6e4a9b9c03f0.jpg\n│   └── 9deadf98-c274-4c3c-8412-9fa0a7b31821.jpg\n├── flax_grains\n│   ├── 00a9b780-f098-44c5-aca7-5c77501e18a8.jpg\n│   ├── 07e8fdca-1759-40bc-8980-7f4d1e615fdf.jpg\n│   ├── 0ae6225f-2f07-493f-95fe-e4269cbdad04.jpg\n│   ├── 0ed81196-d1a7-43a3-931e-fe89b9900d69.jpg\n│   ├── 1a7003e4-9875-4ea8-a997-72e2aac9609f.jpg\n│   ├── 1d3d59fe-b2be-4b3a-9591-23f0e8fc3050.jpg\n│   ├── 1e026706-6791-4c23-b303-6dfb992de42a.jpg\n│   ├── 1ef7aa9f-6d88-42c0-a368-c412922c01ad.jpg\n│   ├── 2bd6eeee-17d9-404d-8773-5d57e58f64ed.jpg\n│   ├── 2f14ceef-5911-44b7-a6bc-18ddde1af0e1.jpg\n│   ├── 3b1121ba-0537-4633-bd51-072b735b0505.jpg\n│   ├── 3b8afc6f-1d77-4a5a-94c6-f711db3ddeba.jpg\n│   ├── 3d0d5f74-b940-42a6-a25c-015d4173f008.jpg\n│   ├── 3d17e772-6f86-4da7-a63a-c62bee734473.jpg\n│   ├── 3d7da214-4fb3-47a6-9537-94594c2d5ec9.jpg\n│   ├── 3e655e2f-4fe4-45d9-850f-bfe3e8745efb.jpg\n│   ├── 3eca5ca7-32a4-4d9f-a2a2-0935bac4515d.jpg\n│   ├── 4a687771-5efe-4d17-b2d9-dcec925b2303.jpg\n│   ├── 4bb0e537-f199-4d0a-8a39-d83d4c9701c0.jpg\n│   ├── 4c268db3-5281-44f0-868e-906f7f1272c4.jpg\n│   ├── 4dfccab2-1131-45b5-b7c9-4b0b1b4351b5.jpg\n│   ├── 4e52db5c-7995-48ee-9403-cff399d58478.jpg\n│   ├── 5a656b43-cc88-42a3-baa2-4570191311c3.jpg\n│   ├── 5aa4e11b-70df-427a-b385-6b83159d493a.jpg\n│   ├── 5ae8b265-9e47-4b8e-8188-add077c06ceb.jpg\n│   ├── 5b8d4be8-018a-4352-9ce7-dc8ad05ee212.jpg\n│   ├── 5d46b89e-55ba-488d-9943-72fee6d7703b.jpg\n│   ├── 5d6a82d3-73b0-47f2-8e1d-2608e9f50801.jpg\n│   ├── 5fecda17-4962-4993-9b1b-53fcc63f9817.jpg\n│   ├── 6ab11a67-acdf-45cb-a137-512a54c1b186.jpg\n│   ├── 6aec1433-98ee-447a-aadb-42c5bdfd1c72.jpg\n│   ├── 6ba1454f-bad6-4b1b-b01c-bbee963d01f1.jpg\n│   ├── 6bd11461-3ccc-4515-b4b4-8bdeae3476db.jpg\n│   ├── 6cfef61f-d030-43be-aeaf-8e4982bf1ebf.jpg\n│   ├── 6d40d5e9-1f86-4c3b-bfc6-8031c52bd804.jpg\n│   ├── 6e258ac8-8bf4-4351-906f-4fb8b8d37adb.jpg\n│   ├── 6f1c0231-ba12-472d-bd0a-fa505aa84563.jpg\n│   ├── 6fe29997-6522-46e3-92b3-1dcbf0549cb8.jpg\n│   ├── 7b7b10f2-bb3a-4de5-85b5-fe58c1849f15.jpg\n│   ├── 7e1b2853-e6f9-42fb-ab72-6613200f5d61.jpg\n│   ├── 8dae31df-8b4f-48f1-96dd-ac8e584fdd1b.jpg\n│   ├── 8ff14fb7-245b-4609-b34e-0bdcb532a7b5.jpg\n│   ├── 8ff43058-f7f3-4bec-acff-9feabd9eaddd.jpg\n│   ├── 9b158211-ec56-4938-ad4c-68f35f8fcc7c.jpg\n│   ├── 9b8c1000-1a2a-4595-8bff-455cedac64af.jpg\n│   ├── 9bdadeba-444a-4e16-9a7b-ebf19178f334.jpg\n│   ├── 9cfb5cf6-87e6-4705-9d28-bb8e316a3809.jpg\n│   ├── 9da02a71-c64b-42e4-8767-98211ecf957f.jpg\n│   ├── 9db67654-2fed-4dd0-b73c-6e4a9b9c03f0.jpg\n│   └── 9deadf98-c274-4c3c-8412-9fa0a7b31821.jpg\n├── flax_leaves\n│   ├── IMG_6072.JPG\n│   ├── IMG_6073.JPG\n│   ├── IMG_6074.JPG\n│   ├── IMG_6075.JPG\n│   ├── IMG_6076.JPG\n│   ├── IMG_6077.JPG\n│   ├── IMG_6078.JPG\n│   ├── IMG_6079.JPG\n│   ├── IMG_6080.JPG\n│   ├── IMG_6081.JPG\n│   ├── IMG_6082.JPG\n│   ├── IMG_6083.JPG\n│   ├── IMG_6084.JPG\n│   ├── IMG_6085.JPG\n│   ├── IMG_6086.JPG\n│   ├── IMG_6087.JPG\n│   ├── IMG_6088.JPG\n│   ├── IMG_6089.JPG\n│   ├── IMG_6090.JPG\n│   ├── IMG_6091.JPG\n│   ├── IMG_6092.JPG\n│   ├── IMG_6093.JPG\n│   ├── IMG_6094.JPG\n│   ├── IMG_6095.JPG\n│   ├── IMG_6096.JPG\n│   ├── IMG_6097.JPG\n│   ├── IMG_6098.JPG\n│   ├── IMG_6099.JPG\n│   ├── IMG_6100.JPG\n│   ├── IMG_6101.JPG\n│   ├── IMG_6102.JPG\n│   ├── IMG_6103.JPG\n│   ├── IMG_6104.JPG\n│   ├── IMG_6105.JPG\n│   ├── IMG_6106.JPG\n│   ├── IMG_6107.JPG\n│   ├── IMG_6108.JPG\n│   ├── IMG_6109.JPG\n│   ├── IMG_6110.JPG\n│   ├── IMG_6111.JPG\n│   ├── IMG_6112.JPG\n│   ├── IMG_6113.JPG\n│   ├── IMG_6114.JPG\n│   ├── IMG_6115.JPG\n│   ├── IMG_6116.JPG\n│   ├── IMG_6117.JPG\n│   ├── IMG_6118.JPG\n│   ├── IMG_6119.JPG\n│   ├── IMG_6120.JPG\n│   ├── IMG_6121.JPG\n│   ├── IMG_6122.JPG\n│   ├── IMG_6123.JPG\n│   ├── IMG_6124.JPG\n│   ├── IMG_6125.JPG\n│   ├── IMG_6126.JPG\n│   ├── IMG_6127.JPG\n│   ├── IMG_6128.JPG\n│   ├── IMG_6129.JPG\n│   ├── IMG_6130.JPG\n│   ├── IMG_6131.JPG\n│   ├── IMG_6132.JPG\n│   ├── IMG_6133.JPG\n│   ├── IMG_6134.JPG\n│   ├── IMG_6135.JPG\n│   ├── IMG_6136.JPG\n│   ├── IMG_6137.JPG\n│   ├── IMG_6138.JPG\n│   ├── IMG_6139.JPG\n│   ├── IMG_6140.JPG\n│   ├── IMG_6141.JPG\n│   ├── IMG_6142.JPG\n│   ├── IMG_6143.JPG\n│   ├── IMG_6144.JPG\n│   ├── IMG_6145.JPG\n│   ├── IMG_6146.JPG\n│   ├── IMG_6147.JPG\n│   ├── IMG_6148.JPG\n│   ├── IMG_6149.JPG\n│   ├── IMG_6150.JPG\n│   ├── IMG_6151.JPG\n│   ├── IMG_6152.JPG\n│   ├── IMG_6153.JPG\n│   ├── IMG_6154.JPG\n│   ├── IMG_6155.JPG\n│   ├── IMG_6156.JPG\n│   ├── IMG_6157.JPG\n│   ├── IMG_6158.JPG\n│   ├── IMG_6159.JPG\n│   ├── IMG_6160.JPG\n│   ├── IMG_6161.JPG\n│   ├── IMG_6162.JPG\n│   ├── IMG_6163.JPG\n│   ├── IMG_6164.JPG\n│   ├── IMG_6165.JPG\n│   ├── IMG_6166.JPG\n│   ├── IMG_6167.JPG\n│   ├── IMG_6168.JPG\n│   ├── IMG_6169.JPG\n│   ├── IMG_6170.JPG\n│   ├── IMG_6171.JPG\n│   ├── IMG_6172.JPG\n│   ├── IMG_6173.JPG\n│   ├── IMG_7287.JPG\n│   ├── IMG_7288.JPG\n│   ├── IMG_7289.JPG\n│   ├── IMG_7290.JPG\n│   ├── IMG_7291.JPG\n│   ├── IMG_7292.JPG\n│   ├── IMG_7293.JPG\n│   ├── IMG_7294.JPG\n│   ├── IMG_7295.JPG\n│   ├── IMG_7296.JPG\n│   ├── IMG_7297.JPG\n│   ├── IMG_7298.JPG\n│   ├── IMG_7299.JPG\n│   ├── IMG_7300.JPG\n│   ├── IMG_7301.JPG\n│   ├── IMG_7302.JPG\n│   ├── IMG_7303.JPG\n│   ├── IMG_7304.JPG\n│   ├── IMG_7305.JPG\n│   ├── IMG_7306.JPG\n│   ├── IMG_7307.JPG\n│   ├── IMG_7308.JPG\n│   ├── IMG_7309.JPG\n│   ├── IMG_7310.JPG\n│   ├── IMG_7311.JPG\n│   ├── IMG_7312.JPG\n│   ├── IMG_7313.JPG\n│   ├── IMG_7314.JPG\n│   ├── IMG_7315.JPG\n│   ├── IMG_7316.JPG\n│   ├── IMG_7317.JPG\n│   ├── IMG_7318.JPG\n│   ├── IMG_7319.JPG\n│   ├── IMG_7320.JPG\n│   ├── IMG_7321.JPG\n│   ├── IMG_7322.JPG\n│   ├── IMG_7323.JPG\n│   ├── IMG_7324.JPG\n│   ├── IMG_7325.JPG\n│   ├── IMG_7326.JPG\n│   ├── IMG_7327.JPG\n│   ├── IMG_7328.JPG\n│   ├── IMG_7329.JPG\n│   ├── IMG_7330.JPG\n│   ├── IMG_7331.JPG\n│   ├── IMG_7332.JPG\n│   ├── IMG_7333.JPG\n│   ├── IMG_7334.JPG\n│   ├── IMG_7335.JPG\n│   ├── IMG_7336.JPG\n│   ├── IMG_7337.JPG\n│   ├── IMG_7338.JPG\n│   ├── IMG_7339.JPG\n│   ├── IMG_7340.JPG\n│   ├── IMG_7341.JPG\n│   ├── IMG_7342.JPG\n│   ├── IMG_7343.JPG\n│   ├── IMG_7344.JPG\n│   ├── IMG_7345.JPG\n│   ├── IMG_7346.JPG\n│   ├── IMG_7347.JPG\n│   ├── IMG_7348.JPG\n│   ├── IMG_7349.JPG\n│   ├── IMG_7350.JPG\n│   ├── IMG_7351.JPG\n│   ├── IMG_7352.JPG\n│   ├── IMG_7353.JPG\n│   ├── IMG_7354.JPG\n│   ├── IMG_7355.JPG\n│   ├── IMG_7356.JPG\n│   ├── IMG_7357.JPG\n│   ├── IMG_7358.JPG\n│   ├── IMG_7359.JPG\n│   ├── IMG_7360.JPG\n│   ├── IMG_7361.JPG\n│   ├── IMG_7362.JPG\n│   ├── IMG_7363.JPG\n│   ├── IMG_7364.JPG\n│   ├── IMG_7365.JPG\n│   ├── IMG_7366.JPG\n│   ├── IMG_7367.JPG\n│   ├── IMG_7368.JPG\n│   ├── IMG_7369.JPG\n│   ├── IMG_7370.JPG\n│   ├── IMG_7371.JPG\n│   ├── IMG_7372.JPG\n│   ├── IMG_7373.JPG\n│   ├── IMG_7374.JPG\n│   ├── IMG_7375.JPG\n│   ├── IMG_7376.JPG\n│   ├── IMG_7377.JPG\n│   ├── IMG_7378.JPG\n│   ├── IMG_7379.JPG\n│   ├── IMG_7380.JPG\n│   ├── IMG_7381.JPG\n│   ├── IMG_7382.JPG\n│   ├── IMG_7383.JPG\n│   ├── IMG_7384.JPG\n│   ├── IMG_7385.JPG\n│   ├── IMG_7386.JPG\n│   ├── IMG_7387.JPG\n│   └── IMG_7388.JPG\n├── flax_ref.JPG\n├── fungi.jpg\n├── leaves.jpg\n├── maize.jpg\n├── paper.png\n├── pollen.jpg\n├── potato.jpg\n├── Rplots.pdf\n├── sevsoja\n│   ├── soy_1.jpg\n│   ├── soy_10.jpg\n│   ├── soy_11.jpg\n│   ├── soy_12.jpg\n│   ├── soy_13.jpg\n│   ├── soy_14.jpg\n│   ├── soy_15.jpg\n│   ├── soy_16.jpg\n│   ├── soy_17.jpg\n│   ├── soy_18.jpg\n│   ├── soy_19.jpg\n│   ├── soy_2.jpg\n│   ├── soy_20.jpg\n│   ├── soy_21.jpg\n│   ├── soy_22.jpg\n│   ├── soy_23.jpg\n│   ├── soy_24.jpg\n│   ├── soy_25.jpg\n│   ├── soy_26.jpg\n│   ├── soy_27.jpg\n│   ├── soy_28.jpg\n│   ├── soy_29.jpg\n│   ├── soy_3.jpg\n│   ├── soy_30.jpg\n│   ├── soy_31.jpg\n│   ├── soy_32.jpg\n│   ├── soy_33.jpg\n│   ├── soy_34.jpg\n│   ├── soy_35.jpg\n│   ├── soy_36.jpg\n│   ├── soy_37.jpg\n│   ├── soy_38.jpg\n│   ├── soy_39.jpg\n│   ├── soy_4.jpg\n│   ├── soy_40.jpg\n│   ├── soy_41.jpg\n│   ├── soy_42.jpg\n│   ├── soy_43.jpg\n│   ├── soy_44.jpg\n│   ├── soy_45.jpg\n│   ├── soy_46.jpg\n│   ├── soy_47.jpg\n│   ├── soy_48.jpg\n│   ├── soy_49.jpg\n│   ├── soy_5.jpg\n│   ├── soy_50.jpg\n│   ├── soy_6.jpg\n│   ├── soy_7.jpg\n│   ├── soy_8.jpg\n│   └── soy_9.jpg\n├── sev_leaves.JPG\n├── smaller\n│   ├── 20231001_144226.jpg\n│   ├── 20231001_153711.jpg\n│   ├── 20231001_160425.jpg\n│   ├── 20231003_144448.jpg\n│   ├── 20231005_112708.jpg\n│   └── 20231005_140911.jpg\n├── videira.png\n├── videira_background.jpg\n├── videira_disease.jpg\n├── videira_healthy.jpg\n├── _quarto.yml\n└── _site\n    ├── 00_about.html\n    ├── 01_dia1.html\n    ├── 01_dia1_files\n    ├── capa.jpg\n    ├── index.html\n    ├── paper.png\n    ├── search.json\n    └── site_libs\n\n\nThe material in HTML (_site/index.html) will give you access to the site, where you can view all examples, with codes and outputs. To reproduce the material, simply use the *.qmd files.\nFor reproduction, it is suggested to set the htp_cbmp2025 folder as the default directory. You can easily set the directory by running the following command, assuming you have the 00_about.qmd script open.\n\npliman::set_wd_here()\n\n\n5 License\nThis content is licensed under a CC BY-NC-SA 4.0. The human-readable summary of the license states that you have the right to:\n\n\nShare — copy and redistribute the material in any medium or format.\n\nAdapt — remix, transform, and build upon the material.\n\nAttribution — You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\nUnder the following terms\nNon-Commercial — You may not use the material for commercial purposes.\nShareAlike — If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.\nNo additional restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits."
  }
]